{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbiXnash/Big-Mart-Sales-Prediction/blob/main/Big_Mart_Sales_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sIHaN1zjLI6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv('/content/train_ds.csv.zip') #loading the train set\n",
        "df2=pd.read_csv('/content/test_ds.csv.zip')  #loading the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-apLbQLjo69"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcTh_VSskAGl"
      },
      "outputs": [],
      "source": [
        "# Checking Null values in Train Set\n",
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BoPjDo1w8sI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt13zF_ekfCH"
      },
      "outputs": [],
      "source": [
        "# Checking Null values in Test Set\n",
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smVao9LEkqhM"
      },
      "outputs": [],
      "source": [
        "#Filling the Null values in 'Item_Weight' column with the average weight\n",
        "df1['Item_Weight'].fillna(value=df1['Item_Weight'].mean(),inplace=True)\n",
        "df2['Item_Weight'].fillna(value=df2['Item_Weight'].mean(),inplace=True)\n",
        "\n",
        "#Filling the Null values in 'Outlet_Size' column with \"Unknown\"\n",
        "df1['Outlet_Size'].fillna(value='Unknown',inplace=True)\n",
        "df2['Outlet_Size'].fillna(value='Unknown',inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDXRTgxbnQ8O"
      },
      "outputs": [],
      "source": [
        "#Checking the Null values in Train set\n",
        "df1.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZwaOI6Tn-w5"
      },
      "outputs": [],
      "source": [
        "#Checking the Null values in Test set\n",
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txnDsh-5sRyX"
      },
      "outputs": [],
      "source": [
        "df1['Item_Type'].value_counts()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Item_Type'].value_counts().index, df1['Item_Type'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Item_Type Distribution')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Item_Type')\n",
        "plt.ylabel('Frequency')\n",
        "print('Item_Type:\\n',df1['Item_Type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtAG-MDmoi3n"
      },
      "outputs": [],
      "source": [
        "# Let's categorize 'Item_Type' into 'Non consumables', 'Drinks' and 'Foods' according to the 'Item_Identifier'\n",
        "def item_identify(cols):\n",
        "  item_id=cols[0]\n",
        "  item_type=cols[1]\n",
        "\n",
        "  if item_id[:2] == 'NC':\n",
        "    return 'Non Consumables'\n",
        "  elif item_id[:2] == 'DR':\n",
        "    return 'Drinks'\n",
        "  else:\n",
        "    return 'Foods'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02dLOWnDnuJ6"
      },
      "outputs": [],
      "source": [
        "df1['Item_Type']=df1[['Item_Identifier','Item_Type']].apply(item_identify,axis=1)\n",
        "df2['Item_Type']=df2[['Item_Identifier','Item_Type']].apply(item_identify,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meO8duRgrjBi"
      },
      "outputs": [],
      "source": [
        "df1['Item_Type'].value_counts()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Item_Type'].value_counts().index, df1['Item_Type'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Item_Type Distribution')\n",
        "#plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Item_Type')\n",
        "plt.ylabel('Frequency')\n",
        "print('Item_Type:\\n',df1['Item_Type'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP47jncxoLQW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Item_Fat_Content'].value_counts().index, df1['Item_Fat_Content'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Item_Fat_Content Distribution')\n",
        "plt.xlabel('Item_Fat_Content')\n",
        "plt.ylabel('Frequency')\n",
        "print('Item_Fat_Content:\\n',df1['Item_Fat_Content'].value_counts())\n",
        "#df1['Item_Fat_Content'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STQtuaWUq1S_"
      },
      "outputs": [],
      "source": [
        "# From the above graph we can see that there are actually two classes in 'Item_Fat_Content'. But some of the items are non consumables.\n",
        "def item_fat(cols):\n",
        "  fat=cols[0]\n",
        "  typ=cols[1]\n",
        "\n",
        "  if (fat=='Low Fat' or fat=='LF' or fat=='low fat') and (typ=='Foods' or typ=='Drinks'):\n",
        "    return 'Low Fat'\n",
        "  elif (fat=='Regular' or fat=='reg') and (typ=='Foods' or typ=='Drinks'):\n",
        "    return 'Regular'\n",
        "  else:\n",
        "    return 'Non Edible'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJD1elSTrPLb"
      },
      "outputs": [],
      "source": [
        "df1['Item_Fat_Content']=df1[['Item_Fat_Content','Item_Type']].apply(item_fat,axis=1)\n",
        "df2['Item_Fat_Content']=df2[['Item_Fat_Content','Item_Type']].apply(item_fat,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ1Gy63gsIL8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Item_Fat_Content'].unique(), df1['Item_Fat_Content'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Item_Fat_Content Distribution')\n",
        "plt.xlabel('Item_Fat_Content')\n",
        "plt.ylabel('Frequency')\n",
        "print('Item_Fat_Content:\\n',df1['Item_Fat_Content'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0x4-38rvnn3"
      },
      "outputs": [],
      "source": [
        "df1['Outlet_Size'].value_counts()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Outlet_Size'].value_counts().index, df1['Outlet_Size'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Outlet_Size')\n",
        "#plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Outlet_Size')\n",
        "plt.ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSv1S9lEtYDM"
      },
      "outputs": [],
      "source": [
        "df1['Outlet_Location_Type'].value_counts()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Outlet_Location_Type'].value_counts().index, df1['Outlet_Location_Type'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Outlet_Location_Type Distribution')\n",
        "#plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Outlet_Location_Type')\n",
        "plt.ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubaaqOJ3wMWc"
      },
      "outputs": [],
      "source": [
        "df1['Outlet_Type'].value_counts()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.bar(df1['Outlet_Type'].value_counts().index, df1['Outlet_Type'].value_counts(), width=0.5, bottom=None, align='center', data=df1)\n",
        "plt.title('Outlet_Type')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Outlet_Type')\n",
        "plt.ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF8oGMm-z0TI"
      },
      "outputs": [],
      "source": [
        "df1['Item_Visibility'].value_counts().head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKzzDeC0xlei"
      },
      "outputs": [],
      "source": [
        "#The column 'Item_Visibility' has lots of 0 values. Let's fill this values with the mean value\n",
        "df1['Item_Visibility'].mask(df1['Item_Visibility']== 0,df1['Item_Visibility'].mean(),inplace=True)\n",
        "df2['Item_Visibility'].mask(df2['Item_Visibility']== 0,df2['Item_Visibility'].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olWdkDIR11WC"
      },
      "outputs": [],
      "source": [
        "#Let's add a new feature that would have the number of years the outlet has been in operation till 2013. (This dataset is from 2013).\n",
        "def num_years(col):\n",
        "  return 2013-col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-A1COuw1-Hf"
      },
      "outputs": [],
      "source": [
        "df1['Years_of_Operation']=df1['Outlet_Establishment_Year'].apply(num_years)\n",
        "df2['Years_of_Operation']=df2['Outlet_Establishment_Year'].apply(num_years)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9gV1tJmjPAZ"
      },
      "outputs": [],
      "source": [
        "# One hot encoding the categorical variables in both train and test set\n",
        "item_fat_content=pd.get_dummies(df1['Item_Fat_Content'])\n",
        "item_type=pd.get_dummies(df1['Item_Type'])\n",
        "outlet_size=pd.get_dummies(df1['Outlet_Size'])\n",
        "outlet_location_type=pd.get_dummies(df1['Outlet_Location_Type'])\n",
        "output_type=pd.get_dummies(df1['Outlet_Type'])\n",
        "\n",
        "item_fat_content_test=pd.get_dummies(df2['Item_Fat_Content'])\n",
        "item_type_test=pd.get_dummies(df2['Item_Type'])\n",
        "outlet_size_test=pd.get_dummies(df2['Outlet_Size'])\n",
        "outlet_location_type_test=pd.get_dummies(df2['Outlet_Location_Type'])\n",
        "output_type_test=pd.get_dummies(df2['Outlet_Type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMgvsYcoopms"
      },
      "outputs": [],
      "source": [
        "train=df1\n",
        "train=pd.concat([train,item_fat_content,item_type,outlet_size,outlet_location_type,output_type],axis=1)\n",
        "train.drop(['Item_Identifier','Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Size', 'Outlet_Location_Type',\n",
        "       'Outlet_Type'],axis=1,inplace=True)\n",
        "test=df2\n",
        "test=pd.concat([test,item_fat_content_test,item_type_test,outlet_size_test,outlet_location_type_test,output_type_test],axis=1)\n",
        "test.drop(['Item_Identifier','Item_Fat_Content','Item_Type','Outlet_Identifier','Outlet_Establishment_Year','Outlet_Size', 'Outlet_Location_Type',\n",
        "       'Outlet_Type'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8FW2ywRb2gv"
      },
      "outputs": [],
      "source": [
        "x=train.drop(['Item_Outlet_Sales'],axis=1)\n",
        "y=train['Item_Outlet_Sales']\n",
        "x_test=test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0-tMNTgcjbt"
      },
      "outputs": [],
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x=StandardScaler()\n",
        "x=sc_x.fit_transform(x)\n",
        "\n",
        "x_test=sc_x.fit_transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlfTq98h6_0D"
      },
      "outputs": [],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfYyuuW3eIUx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.1,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5Aq8b5iSFSe"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fesPw1DJocIF"
      },
      "source": [
        "## **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnlyidEVjimv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf=RandomForestRegressor(n_estimators=400,max_depth=6, min_samples_leaf=76,n_jobs=4)\n",
        "rf.fit(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uiu-eMRjMBZ"
      },
      "outputs": [],
      "source": [
        "predictions1=rf.predict(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubqRLkubjVcu"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_val,predictions1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sajksrwTjYEj"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.distplot((y_val-predictions1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv-VrLlajc4X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error: ',metrics.mean_absolute_error(y_val,predictions1))\n",
        "print('Mean Squared Error: ',metrics.mean_squared_error(y_val,predictions1))\n",
        "print('Root Mean Squared Error: ',np.sqrt(metrics.mean_squared_error(y_val,predictions1)))\n",
        "print('Explained Variance Score: ',metrics.explained_variance_score(y_val,predictions1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8doJIjNSrrq"
      },
      "outputs": [],
      "source": [
        "r2_score = metrics.r2_score(y_val, predictions1)\n",
        "print('R^2 Score:', r2_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1EeDnSe-zAN"
      },
      "outputs": [],
      "source": [
        "#Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Create the parameter grid based on the results of random search\n",
        "param_grid = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': range(1,15,1),\n",
        "    'min_samples_leaf': range(70,80,1),\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': range(100,500,100)\n",
        "}\n",
        "\n",
        "# Create a based model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
        "                          cv = 10, n_jobs = 4, verbose = 2,scoring='neg_mean_absolute_error')\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "grid_search.best_params_,grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46cA81KgS7eJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}